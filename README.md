# Video-based Cross-modal Auxiliary Network for Multimodal Sentiment Analysis
The video-based cross-modal auxiliary network (VCAN) consists of two components: the Audio Feature Map Module (AFMM), which enhances multi-scale acoustic sentiment representation; and the Cross-Modal Selection Module (CMSM), which aims to improve the interactivity of audiovisual modalities and eliminate redundant computations.

## GettING Started
These instructions will providee you with a core copy of the VCAN. you can adapt it and run on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.
### Prerequisites
What things you need to install the software and how to install them
```
Give examples
```
